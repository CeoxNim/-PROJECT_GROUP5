**以点带面之试谈$GANS$及其变体**

$@author~崔轩宁|严丽君|丁乾坤|黄埸瀚$

**背景：**

自从$GAN$生成对抗网络被提出以来，以其为基础的衍生变体也越来越多。它们聚焦于不同的细分领域，共同搭建其$GANS$的网络世界。我们小组的论文分工本是一篇数学论文$《PRIMES~IS~IN~P》$,在听其他组的同学做了有关$GANS$的基本介绍后，对其萌生了兴趣，并决心一同探究其诸多变体的不同应用情境，于比较分析中进一步领会生成对抗网络的核心内涵。



**工作内容：**

目录：
$$
GAN-InfoGAN-ACGAN-SAGAN-SinGAN-LSGAN
$$
简介：

## infoGAN

信息最大化生成对抗网络$infoGAN$的提出是为了无监督学习得到可分解的特征表示。由于原始的$GAN$模型的生成器的输入仅仅是一个连续的噪声向量$z$，没有加任何限制，所以是以一种高度混合的方式使用$z$，导致生成器无法将$z$的维度和数据的语义特征联系起来。如果考虑将输入的噪声向量中混入隐含编码$c$，不断训练学习使得$c$和$x$之间具备密切的关系，即可使得其特征被提取出来，从而生成具有显著特征的图片。

## ACGAN

$ACGAN$也是为了能够生成具有指定特征的图片，不同之处在于$ACGAN$所传入生成器的不仅仅是噪声和隐含编码$c$，还包含对应的类别标签$c\sim p_c$，生成器使用上述来生成样本，从而为有监督学习的一种。标签的加入使得对指定特征的提取更加精准，训练效果也更好些。

## SAGAN

$SAGAN$的贡献在于自适应机制$self-attention$的引入，其作用是更好地学习到全局特征之间的依赖关系。因为传统的$GAN$模型很容易学习到纹理特征，如皮毛、天空、草地，但却不容易学习到特定的结构和几何特征，这主要是因为感受野的限制造成的。$self-attention$通过直接计算图像中任意两个像素点之间的关系，一步到位地获取图像地全局几何特征，从而生成看起来更加真实的图片。

## SinGAN

$SinGAN$的优点是解决了训练集不足的问题，可以仅仅依靠输入一张图片并根据这一张图片进行训练，得到效果较好的生成对抗网络。其训练出来的模型可以用于生成任意大小的以假乱真的图片，可以进行$super~resolution$，以及生成$animation$等诸多操作。当然，由于训练集仅一张图片，其效果在某一个具体的细分领域，可能比不上相应的$GAN$变体，但在训练集不足的情况下尤其有效。

## LSGAN

$LSGAN$试图使用不同的距离度量来构建一个更加稳定而且收敛更快的、生成图片质量更高的对抗网络，即通过对其背后的数学原理分析，优化其损失函数，用最小二乘来代替原始的交叉熵。虽然看似简单，但其背后的数学原理以及逻辑意义仍然值得我们思考。



**项目报告及效果图：**

大致分工如下：

崔轩宁：$InfoGAN$与$ACGAN$及其拓展

严丽君：$SAGAN$及其拓展

丁乾坤：$SinGAN$及其拓展

黄埸瀚：$LSGAN$及其拓展

具体细节详见每个人的分文件夹内的$md$文件。

对于课堂老师建议的不同变体同一训练集测试，我们用$MNIST$进行了如下测试，在最终收敛的情况下得到效果如下：

$GAN$

<img src="img\gan.png" style="zoom:50%;" />

$InfoGAN$（优化前）

<img src="img\infogan1.png" style="zoom:50%;" />

$InfoGAN$（优化后）

<img src="img\infogan.png" style="zoom:33%;" />

$ACGAN$

<img src="img\acgan.png" style="zoom:33%;" />

$SinGAN$

<img src="img\singan.png" style="zoom: 50%;" />

$LSGAN$ 

<img src="img\lsgan.png" style="zoom:50%;" />